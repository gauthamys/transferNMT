{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauthamys/transferNMT/blob/main/kan_to_eng_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "# Neural machine translation with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmSR1FaqKrl"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DGFTkuRvzWqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08095982-684a-4c9c-84c0-28a6f8ca61b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.25.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G-vnFuYS8Pqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1811e5c8-4954-4444-9530-180cfd5f579e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KPJ9J7iPUchc"
      },
      "outputs": [],
      "source": [
        "use_builtins = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title Shape checker\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjUROhJfH3ML"
      },
      "source": [
        "## The data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfodePkj3jEa"
      },
      "source": [
        "### Download and prepare the dataset\n",
        "\n",
        "\n",
        "1. Add a *start* and *end* token to each sentence.\n",
        "2. Clean the sentences by removing special characters.\n",
        "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "4. Pad each sentence to a maximum length."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_kn = open('./drive/MyDrive/data/smallest.kn', encoding='utf-8').readlines()\n",
        "small_en = open('./drive/MyDrive/data/smallest.en').readlines()\n",
        "\n",
        "# for pair in list(zip(small_en[:5], small_kn[:5])):\n",
        "#     print(pair[0][:-2],'\\t',pair[1][:-2])\n",
        "\n",
        "pairs = []\n",
        "for pair in list(zip(small_kn, small_en)):\n",
        "  k, e = pair[0].strip(), pair[1].strip()\n",
        "  pairs.append(f'{k}\\t{e}\\n')\n",
        "\n",
        "with open('./drive/MyDrive/data/kan.txt', 'w') as kan:\n",
        "  kan.write(''.join(pairs))\n",
        "\n",
        "len(pairs)"
      ],
      "metadata": {
        "id": "wITWLAQ58sa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0208c6-40bc-4641-d687-9cca3defa412"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"./drive/MyDrive/data/kan.txt\"\n",
        "batch_size = 128  # Batch size for training.\n",
        "epochs = 25  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk."
      ],
      "metadata": {
        "id": "Aec2pbfr81Vx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    line.strip()\n",
        "    input_text, target_text = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)"
      ],
      "metadata": {
        "id": "ht8lAQWP-7p_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfVWx3WaI5Df"
      },
      "source": [
        "From these arrays of strings you can create a `tf.data.Dataset` of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TqHsArVZ3jFS"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(input_texts)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_texts, target_texts)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f3604f-053f-45f9-9842-157a3f03150c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xe0\\xb2\\xb9\\xe0\\xb3\\x86\\xe0\\xb3\\x95\\xe0\\xb2\\x97\\xe0\\xb3\\x86 \\xe0\\xb2\\x95\\xe0\\xb2\\xb5\\xe0\\xb2\\x95\\xe0\\xb2\\x9c\\xe0\\xb2\\xbe\\xe0\\xb2\\xb2\\xe0\\xb2\\xb5\\xe0\\xb2\\xa8\\xe0\\xb3\\x8d\\xe0\\xb2\\xa8\\xe0\\xb3\\x81 \\xe0\\xb2\\xa4\\xe0\\xb2\\xaf\\xe0\\xb2\\xbe\\xe0\\xb2\\xb0\\xe0\\xb3\\x81?'\n",
            " b'\\xe0\\xb2\\xb0\\xe0\\xb2\\xbe\\xe0\\xb2\\xaf\\xe0\\xb2\\xb2\\xe0\\xb3\\x8d \\xe0\\xb2\\x8e\\xe0\\xb2\\xa8\\xe0\\xb3\\x8d\\xe2\\x80\\x8c\\xe0\\xb2\\xab\\xe0\\xb3\\x80\\xe0\\xb2\\xb2\\xe0\\xb3\\x8d\\xe0\\xb2\\xa1\\xe0\\xb3\\x8d \\xe0\\xb2\\xac\\xe0\\xb3\\x81\\xe0\\xb2\\xb2\\xe0\\xb3\\x86\\xe0\\xb2\\x9f\\xe0\\xb3\\x8d \\xe0\\xb2\\x9f\\xe0\\xb3\\x8d\\xe0\\xb2\\xb0\\xe0\\xb2\\xaf\\xe0\\xb2\\xb2\\xe0\\xb3\\x8d\\xe0\\xb2\\xb8\\xe0\\xb3\\x8d 350'\n",
            " b'\\xe0\\xb2\\xa6\\xe0\\xb2\\xbf\\xe0\\xb2\\xb2\\xe0\\xb3\\x8d\\xe0\\xb2\\xb2\\xe0\\xb2\\xbf \\xe0\\xb2\\xae\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xa4\\xe0\\xb3\\x81 \\xe0\\xb2\\xac\\xe0\\xb2\\xbf\\xe0\\xb2\\xb9\\xe0\\xb2\\xbe\\xe0\\xb2\\xb0\\xe0\\xb2\\x97\\xe0\\xb2\\xb3\\xe0\\xb3\\x81 \\xe0\\xb2\\xad\\xe0\\xb2\\xbe\\xe0\\xb2\\xb0\\xe0\\xb3\\x80 \\xe0\\xb2\\xaa\\xe0\\xb3\\x86\\xe0\\xb2\\x9f\\xe0\\xb3\\x8d\\xe0\\xb2\\x9f\\xe0\\xb3\\x81 \\xe0\\xb2\\x95\\xe0\\xb3\\x8a\\xe0\\xb2\\x9f\\xe0\\xb3\\x8d\\xe0\\xb2\\x9f\\xe0\\xb2\\xbf\\xe0\\xb2\\xb5\\xe0\\xb3\\x86.'\n",
            " b'\\xe0\\xb2\\xa8\\xe0\\xb2\\xae\\xe0\\xb2\\x97\\xe0\\xb3\\x86 \\xe0\\xb2\\x8e\\xe0\\xb2\\xb2\\xe0\\xb3\\x8d\\xe0\\xb2\\xb2\\xe0\\xb2\\xb5\\xe0\\xb3\\x82 \\xe0\\xb2\\xae\\xe0\\xb2\\xb0\\xe0\\xb3\\x86\\xe0\\xb2\\xa4\\xe0\\xb3\\x81\\xe0\\xb2\\xb9\\xe0\\xb3\\x8b\\xe0\\xb2\\x97\\xe0\\xb3\\x81\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xa4\\xe0\\xb2\\xbf\\xe0\\xb2\\xa6\\xe0\\xb3\\x86.'\n",
            " b'\\xe0\\xb2\\xaa\\xe0\\xb3\\x8d\\xe0\\xb2\\xb0\\xe0\\xb2\\x95\\xe0\\xb2\\xb0\\xe0\\xb2\\xa3\\xe0\\xb2\\xb5\\xe0\\xb2\\xa8\\xe0\\xb3\\x8d\\xe0\\xb2\\xa8\\xe0\\xb3\\x81 \\xe0\\xb2\\x95\\xe0\\xb2\\xbe\\xe0\\xb2\\x82\\xe0\\xb2\\x97\\xe0\\xb3\\x8d\\xe0\\xb2\\xb0\\xe0\\xb3\\x86\\xe0\\xb2\\xb8\\xe0\\xb3\\x8d \\xe0\\xb2\\x95\\xe0\\xb3\\x82\\xe0\\xb2\\xa1 \\xe0\\xb2\\x96\\xe0\\xb2\\x82\\xe0\\xb2\\xa1\\xe0\\xb2\\xbf\\xe0\\xb2\\xb8\\xe0\\xb3\\x81\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xa4\\xe0\\xb2\\xa6\\xe0\\xb3\\x86.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'\\tHow to make the paste?\\n' b'\\tRoyal Enfield Trials 350\\n'\n",
            " b'\\tDelhi and Bihar were stunning setbacks.\\n'\n",
            " b'\\tWe have forgotten all this.\\n'\n",
            " b'\\tCongress too condemned the incident.\\n'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCoxLcuN3bwv"
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwdPcHvzz_a"
      },
      "source": [
        "One of the goals of this tutorial is to build a model that can be exported as a `tf.saved_model`. To make that exported model useful it should take `tf.string` inputs, and return `tf.string` outputs: All the text processing happens inside the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOQ5n55X4uDB"
      },
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upKhKAMK4zzI"
      },
      "source": [
        "The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n",
        "\n",
        "The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n",
        "\n",
        "The `tensorflow_text` package contains a unicode normalize operation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hTllEjK6RSo"
      },
      "source": [
        "Unicode normalization will be the first step in the text standardization function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "chTF5N885F0P"
      },
      "outputs": [],
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-sKsSI7xRZ"
      },
      "source": [
        "#### Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aKn8qd37abi"
      },
      "source": [
        "This standardization function will be wrapped up in a `tf.keras.layers.TextVectorization` layer which will handle the vocabulary extraction and conversion of input text to sequences of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "outputs": [],
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbC6ODP8IK_"
      },
      "source": [
        "The `TextVectorization` layer and many other preprocessing layers have an `adapt` method. This method reads one epoch of the training data, and works a lot like `Model.fix`. This `adapt` method initializes the layer based on the data. Here it determines the vocabulary:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bmsI1Yql8FYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ef0bc8-15f9-4e7d-d071-ff42c0a9bb77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', ',', '?', '!', 's', 'gb']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "input_text_processor.adapt(input_texts)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jlC4xuZnKLBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52fd4dae-dabf-4a82-803c-94510d1d4899"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'the', ',', 'of', 'to', 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(target_texts)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQqlP_s9eIv"
      },
      "source": [
        "Now these layers can convert a batch of strings into a batch of token IDs:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9rUn9G9n78"
      },
      "source": [
        "The `get_vocabulary` method can be used to convert token IDs back to text:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "## The encoder/decoder model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQWx2saImMV"
      },
      "source": [
        "Before getting into it define a few constants for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_a9uNz3-IrF-"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNgVbLSzpsr"
      },
      "source": [
        "### The encoder\n",
        "\n",
        "Start by building the encoder.\n",
        "\n",
        "The encoder:\n",
        "\n",
        "1. Takes a list of token IDs (from `input_text_processor`).\n",
        "3. Looks up an embedding vector for each token (Using a `layers.Embedding`).\n",
        "4. Processes the embeddings into a new sequence (Using a `layers.GRU`).\n",
        "5. Returns:\n",
        "  * The processed sequence. This will be passed to the attention head.\n",
        "  * The internal state. This will be used to initialize the decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RIPHh4O9ixB"
      },
      "source": [
        "The encoder returns its internal state so that its state can be used to initialize the decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45xM_Gl1MgXY"
      },
      "source": [
        "### The attention head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "momiE59lXo6U"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ638eHN4iCK"
      },
      "source": [
        "### The decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZsQJMqNmg_L"
      },
      "source": [
        "Here is the `Decoder` class and its initializer. The initializer creates all the necessary layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "erYvHIgAl8kh"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUTfYHmfmwKH"
      },
      "source": [
        "The `call` method for this layer takes and returns multiple tensors. Organize those into simple container classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7WfSIb2sArRT"
      },
      "outputs": [],
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NChkl2KrnV2y"
      },
      "source": [
        "Here is the implementation of the `call` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PJOi5btHAPNK"
      },
      "outputs": [],
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ay_mTMPfnb2a"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnaw583CpnY"
      },
      "source": [
        "The decoder takes 4 inputs.\n",
        "\n",
        "* `new_tokens` -  The last token generated. Initialize the decoder with the `\"[START]\"` token.\n",
        "* `enc_output` - Generated by the `Encoder`.\n",
        "* `mask` - A boolean tensor indicating where `tokens != 0`\n",
        "* `state` - The previous `state` output from the decoder (the internal state\n",
        "  of the decoder's RNN). Pass `None` to zero-initialize it. The original\n",
        "  paper initializes it from the encoder's final RNN state. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xyru86m914"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that you have all the model components, it's time to start training the model. You'll need:\n",
        "\n",
        "- A loss function and optimizer to perform the optimization.\n",
        "- A training step function defining how to update the model for each input/target batch.\n",
        "- A training loop to drive the training and save checkpoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5AgEBh2S404"
      },
      "source": [
        "### Implement the training step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_G20Te1XSmJ"
      },
      "source": [
        "Start with a model class, the training process will be implemented as the `train_step` method on this model.\n",
        "\n",
        "Here the `train_step` method is a wrapper around the `_train_step` implementation which will come later. This wrapper includes a switch to turn on and off `tf.function` compilation, to make debugging easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WWIyuy71TkJT"
      },
      "outputs": [],
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i0i1x6jwsLm"
      },
      "source": [
        "Overall the implementation for the `Model.train_step` method is as follows:\n",
        "\n",
        "1. Receive a batch of `input_text, target_text` from the `tf.data.Dataset`.\n",
        "2. Convert those raw text inputs to token-embeddings and masks. \n",
        "3. Run the encoder on the `input_tokens` to get the `encoder_output` and `encoder_state`.\n",
        "4. Initialize the decoder state and loss. \n",
        "5. Loop over the `target_tokens`:\n",
        "   1. Run the decoder one step at a time.\n",
        "   2. Calculate the loss for each step.\n",
        "   3. Accumulate the average loss.\n",
        "6. Calculate the gradient of the loss and use the optimizer to apply updates to the model's `trainable_variables`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngBjFw4BU5G7"
      },
      "source": [
        "The `_preprocess` method, added below, implements steps #1 and #2: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZlYE68wzXoA8"
      },
      "outputs": [],
      "source": [
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lHy6hzStrgjQ"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3kvbcArc2y-"
      },
      "source": [
        "The `_train_step` method, added below, handles the remaining steps except for actually running the decoder: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Qs_gsISsYPpY"
      },
      "outputs": [],
      "source": [
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KGwWHIxLrjGR"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._train_step = _train_step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7g40o-mXyt5"
      },
      "source": [
        "The `_loop_step` method, added below, executes the decoder and calculates the incremental loss and new decoder state (`dec_state`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9VrzgwztXzYJ"
      },
      "outputs": [],
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xj3I7VULrk1R"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OA6bCske8TXm"
      },
      "outputs": [],
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "UFUsTKQx0jaH"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2-bgU59jrztQ"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KC8bRv_Gr3H9"
      },
      "outputs": [],
      "source": [
        "translator.use_tf_function = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Emgfgh4tAmJt"
      },
      "outputs": [],
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpObfY22IddU"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "While there's nothing wrong with writing your own custom training loop, implementing the `Model.train_step` method, as in the previous section, allows you to run `Model.fit` and avoid rewriting all that boiler-plate code. \n",
        "\n",
        "This tutorial only trains for a couple of epochs, so use a `callbacks.Callback` to collect the history of batch losses, for plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "J7m4mtnj80sq"
      },
      "outputs": [],
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BQd_esVVoSf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06727f87-b1a0-4cfb-9cbd-bb4ec5b57a87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 88s 501ms/step - batch_loss: 5.1136\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 93s 593ms/step - batch_loss: 4.4437\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 107s 682ms/step - batch_loss: 4.1492\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 107s 683ms/step - batch_loss: 3.8990\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 110s 701ms/step - batch_loss: 3.6589\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 99s 633ms/step - batch_loss: 3.4103\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 90s 571ms/step - batch_loss: 3.1359\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 101s 643ms/step - batch_loss: 2.8285\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 109s 696ms/step - batch_loss: 2.4669\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 78s 500ms/step - batch_loss: 2.0690\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 78s 496ms/step - batch_loss: 1.6998\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 81s 514ms/step - batch_loss: 1.4029\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 81s 515ms/step - batch_loss: 1.1965\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 76s 484ms/step - batch_loss: 1.0652\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 79s 501ms/step - batch_loss: 0.9846\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 77s 493ms/step - batch_loss: 0.9371\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 77s 490ms/step - batch_loss: 0.9071\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 77s 492ms/step - batch_loss: 0.8861\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 77s 490ms/step - batch_loss: 0.8633\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 78s 496ms/step - batch_loss: 0.8551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f39e65e9410>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "train_translator.fit(dataset, epochs=20,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "38rLdlmtQHCm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d125386b-ce91-4c7a-fef6-6a145ebb9de3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.title('Loss per batch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0S_O_RzHmfe"
      },
      "source": [
        "The visible jumps in the plot are at the epoch boundaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Translate\n",
        "\n",
        "Now that the model is trained, implement a function to execute the full `text => text` translation.\n",
        "\n",
        "For this the model needs to invert the `text => token IDs` mapping provided by the `output_text_processor`. It also needs to know the IDs for special tokens. This is all implemented in the constructor for the new class. The implementation of the actual translate method will follow.\n",
        "\n",
        "Overall this is similar to the training loop, except that the input to the decoder at each time step is a sample from the decoder's last prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PO-CLL1LVBbM"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iBQzFZ9uWU79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e14134-8f20-4982-8a03-2421ada39b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59PN-UxqYrU"
      },
      "source": [
        "### Convert token IDs to text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-razg3Aso737"
      },
      "source": [
        "The first method to implement is `tokens_to_text` which converts from token IDs to human readable text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8IjwKTwtmdFf"
      },
      "outputs": [],
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "912aV0K7r90w"
      },
      "outputs": [],
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krBuAapkqNs9"
      },
      "source": [
        "Input some random token IDs and see what it generates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "cWCMHdoS32QN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a27791-5ee9-4abc-9cce-bc97c3f65c24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'battle close', b'belonging starring', b'mohit count',\n",
              "       b'eight lenders', b'needs sourav'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC9De_kAqtaE"
      },
      "source": [
        "### Sample from the decoder's predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5tno-2ksJv6"
      },
      "source": [
        "This function takes the decoder's logit outputs and samples token IDs from that distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8lfuj3GcdD6e"
      },
      "outputs": [],
      "source": [
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "  \n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4DpDnBdBdL9_"
      },
      "outputs": [],
      "source": [
        "Translator.sample = sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwdHfGEfsmy5"
      },
      "source": [
        "Test run this function on some random inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rwLT0nxXym80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b718f8-d3f5-4d92-e5de-e8a9fff655ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[4799],\n",
              "       [ 278],\n",
              "       [3253],\n",
              "       [  21],\n",
              "       [ 122]])>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEWIKFIJ2HWM"
      },
      "source": [
        "### Implement the translation loop\n",
        "\n",
        "Here is a complete implementation of the text to text translation loop.\n",
        "\n",
        "This implementation collects the results into python lists, before using `tf.concat` to join them into tensors.\n",
        "\n",
        "This implementation statically unrolls the graph out to `max_length` iterations.\n",
        "This is okay with eager execution in python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ZmOvVrZmwAxg"
      },
      "outputs": [],
      "source": [
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "    \n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JOmd8Y269MG3"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_unrolled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxYXf3GNKKLS"
      },
      "source": [
        "Run it on a simple input:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'ಸಾಮಾಜಿಕ ಜಾಲತಾಣಗಳಲ್ಲಿ ಅದೆಷ್ಟೊ ವಿಡಿಯೋಗಳು', #Such videos are aplenty on social media channels. \n",
        "    'ಮುಳಗುಂದ ಪೊಲೀಸ್ ಠಾಣಾ ವ್ಯಾಪ್ತಿಯಲ್ಲಿ', # This incident happened within the limits of Mudhol Police Station.\n",
        "])\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "metadata": {
        "id": "hyhWbui0C4Lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0d722b-89fb-4d05-8a58-f86546620dfd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "photo ap\n",
            "located officials of the overnight\n",
            "\n",
            "CPU times: user 801 ms, sys: 244 ms, total: 1.04 s\n",
            "Wall time: 2.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-6cFyqeUPQm"
      },
      "source": [
        "If you want to export this model you'll need to wrap this method in a `tf.function`. This basic implementation has a few issues if you try to do that:\n",
        "\n",
        "1. The resulting graphs are very large and take a few seconds to build, save or load.\n",
        "2. You can't break from a statically unrolled loop, so it will always run `max_length` iterations, even if all the outputs are done. But even then it's marginally faster than eager execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_JhTZ5hOptO-"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkccvHDvXCa8"
      },
      "source": [
        "Run the `tf.function` once to compile it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "_NzrixLvVBjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9651e245-c8a3-4356-efe9-bcb17e9b3e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19.5 s, sys: 544 ms, total: 20.1 s\n",
            "Wall time: 19.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "USJdu00tVFbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7881ffa-aacf-4602-c9ba-ae7792594e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "russia using home\n",
            "no district\n",
            "\n",
            "CPU times: user 127 ms, sys: 11.4 ms, total: 139 ms\n",
            "Wall time: 116 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMA9Pp71nzH9"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rLMNOmsKoXe"
      },
      "source": [
        "\n",
        "\n",
        "Since the model is a subclass of `tf.Module` (through `keras.Model`), and all the functionality for export is compiled in a `tf.function` the model should export cleanly with `tf.saved_model.save`:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP2dNtEXJPEL"
      },
      "source": [
        "Now that the function has been traced it can be exported using `saved_model.save`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "OyvxT5V0_X5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cddb3156-0eaf-42bf-992d-b0847c8c9d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_1_layer_call_fn, encoder_1_layer_call_and_return_conditional_losses, decoder_1_layer_call_fn, decoder_1_layer_call_and_return_conditional_losses, embedding_2_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: translator/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: translator/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(translator, 'translator',\n",
        "                    signatures={'serving_default': translator.tf_translate})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b0AvrNC202qm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "kan_to_eng_lstm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}